{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/bensapirstein/DeepGraphemics.git\n",
    "%cd DeepGraphemics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- EPOCH 1/3 ---\n",
      "train_batch (24.101):   7%|â–‹         | 3/42 [00:24<05:20,  8.21s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m params \u001b[39m=\u001b[39m capsnet_config\n\u001b[1;32m     12\u001b[0m \u001b[39m# Test experiment1 implementation on a few data samples and with a small model\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m experiments\u001b[39m.\u001b[39;49mrun_experiment(\n\u001b[1;32m     14\u001b[0m     \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mmodel_type\u001b[39m}\u001b[39;49;00m\u001b[39m_test_run\u001b[39;49m\u001b[39m'\u001b[39;49m, data_dir\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdatasets/dataset_rotation_std_5/\u001b[39;49m\u001b[39m\"\u001b[39;49m, seed\u001b[39m=\u001b[39;49mseed, bs_train\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, bs_test\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, early_stopping\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m     15\u001b[0m     model_type\u001b[39m=\u001b[39;49mmodel_type, model_config\u001b[39m=\u001b[39;49mparams\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[39m# There should now be a file 'test_run.json' in your `results/` folder.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m# We can use it to load the results of the experiment.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m cfg, fit_res \u001b[39m=\u001b[39m load_experiment(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mresults/\u001b[39m\u001b[39m{\u001b[39;00mmodel_type\u001b[39m}\u001b[39;00m\u001b[39m_test_run.json\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/MLDS/Deep Learning/Final Project/Deep Graphemics/src/experiments.py:73\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(run_name, data_dir, letter, out_dir, seed, device, bs_train, bs_test, batches, epochs, early_stopping, checkpoints, lr, reg, model_type, model_config, **kw)\u001b[0m\n\u001b[1;32m     71\u001b[0m     optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlr, weight_decay\u001b[39m=\u001b[39mreg)\n\u001b[1;32m     72\u001b[0m     trainer \u001b[39m=\u001b[39m training\u001b[39m.\u001b[39mCapsNetTrainer(model, model\u001b[39m.\u001b[39mloss, optimizer, device)\n\u001b[0;32m---> 73\u001b[0m     fit_res \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mfit(dl_train\u001b[39m=\u001b[39;49mtrain_loader, dl_test\u001b[39m=\u001b[39;49mtest_loader, \n\u001b[1;32m     74\u001b[0m                           num_epochs\u001b[39m=\u001b[39;49mepochs, checkpoints\u001b[39m=\u001b[39;49mcheckpoints, max_batches\u001b[39m=\u001b[39;49mbatches, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m     76\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlr, weight_decay\u001b[39m=\u001b[39mreg)\n\u001b[1;32m     79\u001b[0m save_experiment(run_name, out_dir, cfg, fit_res)\n",
      "File \u001b[0;32m~/MLDS/Deep Learning/Final Project/Deep Graphemics/src/training.py:75\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, dl_train, dl_test, num_epochs, checkpoints, early_stopping, print_every, **kw)\u001b[0m\n\u001b[1;32m     72\u001b[0m     verbose \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_print(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m--- EPOCH \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mnum_epochs\u001b[39m}\u001b[39;00m\u001b[39m ---\u001b[39m\u001b[39m\"\u001b[39m, verbose)\n\u001b[0;32m---> 75\u001b[0m train_epoch_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_epoch(dl_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m     76\u001b[0m train_loss\u001b[39m.\u001b[39mextend(train_epoch_result\u001b[39m.\u001b[39mlosses)\n\u001b[1;32m     77\u001b[0m train_acc\u001b[39m.\u001b[39mappend(train_epoch_result\u001b[39m.\u001b[39maccuracy)\n",
      "File \u001b[0;32m~/MLDS/Deep Learning/Final Project/Deep Graphemics/src/training.py:107\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[0;34m(self, dl_train, **kw)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[39mTrain once over a training set (single epoch).\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[39m:param dl_train: DataLoader for the training set.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39m:param kw: Keyword args supported by _foreach_batch.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39m:return: An EpochResult for the epoch.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain(\u001b[39mTrue\u001b[39;00m)  \u001b[39m# set train mode\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_foreach_batch(dl_train, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_batch, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/MLDS/Deep Learning/Final Project/Deep Graphemics/src/training.py:181\u001b[0m, in \u001b[0;36mTrainer._foreach_batch\u001b[0;34m(dl, forward_fn, verbose, max_batches)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_batches):\n\u001b[1;32m    180\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(dl_iter)\n\u001b[0;32m--> 181\u001b[0m     batch_res \u001b[39m=\u001b[39m forward_fn(data)\n\u001b[1;32m    183\u001b[0m     pbar\u001b[39m.\u001b[39mset_description(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpbar_name\u001b[39m}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{\u001b[39;00mbatch_res\u001b[39m.\u001b[39mloss\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    184\u001b[0m     pbar\u001b[39m.\u001b[39mupdate()\n",
      "File \u001b[0;32m~/MLDS/Deep Learning/Final Project/Deep Graphemics/src/training.py:263\u001b[0m, in \u001b[0;36mCapsNetTrainer.train_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    259\u001b[0m     y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    261\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[39m# vae reconstruction\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m output, reconstructions, masked \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(X)\n\u001b[1;32m    265\u001b[0m \u001b[39m# reconstruction error\u001b[39;00m\n\u001b[1;32m    266\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_fn(X, output, y, reconstructions)\n",
      "File \u001b[0;32m~/MLDS/Deep Learning/Final Project/Deep Graphemics/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/MLDS/Deep Learning/Final Project/Deep Graphemics/src/capsnet.py:136\u001b[0m, in \u001b[0;36mCapsNet.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[0;32m--> 136\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdigit_capsules(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprimary_capsules(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv_layer(data)))\n\u001b[1;32m    137\u001b[0m     reconstructions, masked \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(output, data)\n\u001b[1;32m    138\u001b[0m     \u001b[39mreturn\u001b[39;00m output, reconstructions, masked\n",
      "File \u001b[0;32m~/MLDS/Deep Learning/Final Project/Deep Graphemics/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/MLDS/Deep Learning/Final Project/Deep Graphemics/src/capsnet.py:32\u001b[0m, in \u001b[0;36mPrimaryCaps.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 32\u001b[0m     u \u001b[39m=\u001b[39m [capsule(x) \u001b[39mfor\u001b[39;49;00m capsule \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcapsules]\n\u001b[1;32m     33\u001b[0m     u \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(u, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     34\u001b[0m     u \u001b[39m=\u001b[39m u\u001b[39m.\u001b[39mview(x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_routes, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/MLDS/Deep Learning/Final Project/Deep Graphemics/src/capsnet.py:32\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 32\u001b[0m     u \u001b[39m=\u001b[39m [capsule(x) \u001b[39mfor\u001b[39;00m capsule \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapsules]\n\u001b[1;32m     33\u001b[0m     u \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(u, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     34\u001b[0m     u \u001b[39m=\u001b[39m u\u001b[39m.\u001b[39mview(x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_routes, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/MLDS/Deep Learning/Final Project/Deep Graphemics/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/MLDS/Deep Learning/Final Project/Deep Graphemics/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/MLDS/Deep Learning/Final Project/Deep Graphemics/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import src.experiments as experiments\n",
    "from src.experiments import load_experiment\n",
    "from src.plot import plot_fit\n",
    "from configs.config import capsnet_config, vae_config\n",
    "seed = 42\n",
    "\n",
    "model_type = 'capsnet'\n",
    "\n",
    "# model params kwargs\n",
    "params = capsnet_config\n",
    "\n",
    "# Test experiment1 implementation on a few data samples and with a small model\n",
    "experiments.run_experiment(\n",
    "    f'{model_type}_test_run', data_dir=\"datasets/dataset_rotation_std_5/\", seed=seed, bs_train=128, bs_test=128, epochs=3, early_stopping=5,\n",
    "    model_type=model_type, model_config=params\n",
    ")\n",
    "\n",
    "# There should now be a file 'test_run.json' in your `results/` folder.\n",
    "# We can use it to load the results of the experiment.\n",
    "cfg, fit_res = load_experiment(f'results/{model_type}_test_run.json')\n",
    "_, _ = plot_fit(fit_res)\n",
    "\n",
    "# And `cfg` contains the exact parameters to reproduce it\n",
    "print('experiment config: ', cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_exp_results(filename_pattern, results_dir='results'):\n",
    "    fig = None\n",
    "    result_files = glob.glob(os.path.join(results_dir, filename_pattern))\n",
    "    result_files.sort()\n",
    "    if len(result_files) == 0:\n",
    "        print(f'No results found for pattern {filename_pattern}.', file=sys.stderr)\n",
    "        return\n",
    "    for filepath in result_files:\n",
    "        m = re.match('exp\\d_(\\d_)?(.*)\\.json', os.path.basename(filepath))\n",
    "        cfg, fit_res = load_experiment(filepath)\n",
    "        fig, axes = plot_fit(fit_res, fig, legend=m[2],log_loss=True)\n",
    "    del cfg['filters_per_layer']\n",
    "    del cfg['layers_per_block']\n",
    "    print('common config: ', cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
