{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gdown\n",
    "if 'google.colab' in sys.modules:\n",
    "    if 'torch' not in sys.modules:\n",
    "        !pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "    if 'skia-python' not in sys.modules:\n",
    "        !pip3 install skia-python\n",
    "\n",
    "    if os.getcwd() != '/content/DeepGraphemics':\n",
    "        !git clone https://github.com/bensapirstein/DeepGraphemics.git\n",
    "        %cd DeepGraphemics/\n",
    "\n",
    "    url = 'https://drive.google.com/drive/folders/1X3ERUGyhMZo_ZlHApI1XkjcZAVcnTRNd?usp=drive_link'\n",
    "\n",
    "    gdown.download_folder(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip several databases based on category and letter.\n",
    "\n",
    "categories = [\"base\", \"moderate\", \"rotation\", \"rich_moderate\", \"rich_rotation\"]\n",
    "\n",
    "for ds_type in categories:\n",
    "    root_dir = f\"datasets/{ds_type}_dataset\"\n",
    "    if not os.path.exists(root_dir):\n",
    "        zipped_data = f\"{root_dir}.zip\"\n",
    "        !unzip -q $zipped_data -d datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our experiments include:\n",
    "\n",
    "train VAE with latent space dimension 2, 3, 5, 10, 20\n",
    "\n",
    "train with different hidden layer sizes. (optional)\n",
    "\n",
    "train VAE on different datasets: \"base\", \"moderate\", \"rotation\" and rich datasets.\n",
    "\n",
    "train on different letters.\n",
    "\n",
    "train capsnet with different reconstruction loss weights: 0.0005, 0.005, 0.01, 1, 100\n",
    "\n",
    "train capsnet with different datasets: \"base\", \"moderate\", \"rotation\" and rich datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example run of an experiment\n",
    "\n",
    "import src.experiments as experiments\n",
    "from src.experiments import load_experiment\n",
    "from src.plot import plot_fit\n",
    "from configs.config import capsnet_config, vae_config\n",
    "seed = 42\n",
    "\n",
    "model_type = 'vae'\n",
    "\n",
    "# model params kwargs\n",
    "params = vae_config\n",
    "\n",
    "run_name = f'{model_type}_test_run'\n",
    "ds_type = 'base'\n",
    "data_dir = f'datasets/{ds_type}_dataset/'\n",
    "epochs = 10\n",
    "\n",
    "# Test experiment implementation on a few data samples and with a small model\n",
    "experiments.run_experiment(\n",
    "    run_name, data_dir, letter=\"aleph\", seed=seed, \n",
    "    bs_train=128, bs_test=128, epochs=epochs, early_stopping=5,\n",
    "    model_type=model_type, model_config=params\n",
    ")\n",
    "\n",
    "# There should now be a file 'test_run.json' in your `results/` folder.\n",
    "# We can use it to load the results of the experiment.\n",
    "cfg, fit_res = load_experiment(f'results/{run_name}.json')\n",
    "_, _ = plot_fit(fit_res)\n",
    "\n",
    "# And `cfg` contains the exact parameters to reproduce it\n",
    "print('experiment config: ', cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from configs.config import dotdict\n",
    "\n",
    "# hyperparameter search\n",
    "latent_dims = [2, 3, 5, 10]\n",
    "capacity = [64, 128]\n",
    "variational_beta = [0.1, 0.5, 1.0, 2.0]\n",
    "letters = [\"aleph\", \"shin\", \"mem\"]\n",
    "ds_types = [\"base\", \"moderate\", \"rotation\"]\n",
    "\n",
    "for ds_type, letter, latent_dim, cap, beta in itertools.product(ds_types, letters, latent_dims, capacity, variational_beta):\n",
    "    vae_config = dotdict({\n",
    "        'latent_dims': latent_dim,\n",
    "        'capacity': cap,\n",
    "        'variational_beta': beta\n",
    "    })\n",
    "\n",
    "    data_dir = f'datasets/{ds_type}_dataset/'\n",
    "\n",
    "    run_name = f\"vae_{ds_type}_{letter}_{latent_dim}_{cap}_{beta}\"\n",
    "    print(f\"Running {letter} experiment with latent_dim={latent_dim}, capacity={cap}, beta={beta}\")\n",
    "    fit_res = experiments.run_experiment(run_name, data_dir, epochs=5, letter=letter, model_type=\"vae\", model_config=vae_config, save_model=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "\n",
    "def plot_exp_results(filename_pattern, results_dir='results'):\n",
    "    fig = None\n",
    "    result_files = glob.glob(os.path.join(results_dir, filename_pattern))\n",
    "    result_files.sort()\n",
    "    if len(result_files) == 0:\n",
    "        print(f'No results found for pattern {filename_pattern}.', file=sys.stderr)\n",
    "        return\n",
    "    for filepath in result_files:\n",
    "        m = re.match('vae_aleph_(.*)\\.json', os.path.basename(filepath))\n",
    "        cfg, fit_res = load_experiment(filepath)\n",
    "        fig, axes = plot_fit(fit_res, fig, legend=m[1],log_loss=True)\n",
    "    print('common config: ', cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_exp_results(\"vae_base_aleph_*_0.5.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
