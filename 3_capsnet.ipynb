{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    import gdown\n",
    "    if 'torch' not in sys.modules:\n",
    "        !pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "    if 'skia-python' not in sys.modules:\n",
    "        !pip3 install skia-python\n",
    "\n",
    "    if os.getcwd() != '/content/DeepGraphemics':\n",
    "        !git clone https://github.com/bensapirstein/DeepGraphemics.git\n",
    "        %cd DeepGraphemics/\n",
    "\n",
    "    url = 'https://drive.google.com/drive/folders/1X3ERUGyhMZo_ZlHApI1XkjcZAVcnTRNd?usp=drive_link'\n",
    "\n",
    "    gdown.download_folder(url)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip several databases based on category and letter.\n",
    "\n",
    "categories = [\"base\", \"moderate\", \"rotation\", \"rich_moderate\", \"rich_rotation\"]\n",
    "\n",
    "for ds_type in categories:\n",
    "    root_dir = f\"datasets/{ds_type}_dataset\"\n",
    "    if not os.path.exists(root_dir):\n",
    "        zipped_data = f\"{root_dir}.zip\"\n",
    "        !unzip -q $zipped_data -d datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from src.capsnet import CapsNet, ReconstructionNet, CapsNetWithReconstruction, MarginLoss\n",
    "\n",
    "batch_size = 128\n",
    "test_batch_size = 1000\n",
    "epochs = 9\n",
    "save_every = 3\n",
    "lr = 0.001\n",
    "no_cuda = False\n",
    "seed = 42\n",
    "log_interval = 10\n",
    "routing_iterations = 3\n",
    "with_reconstruction = True\n",
    "n_classes = 13\n",
    "\n",
    "cuda = not no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from src.datasets import GraphemesDataset\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "ds_type = \"moderate\"\n",
    "letter = \"aleph\"\n",
    "root_dir = f\"datasets/{ds_type}_dataset\"\n",
    "\n",
    "train_dataset = GraphemesDataset(root_dir, train=True, by_letter=letter, transform=img_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = GraphemesDataset(root_dir, train=False, by_letter=letter, transform=img_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.plot as plot\n",
    "\n",
    "fig, axes = plot.dataset_first_n(train_dataset, 64,\n",
    "                                 show_classes=True,\n",
    "                                 class_labels=train_dataset.classes,\n",
    "                                 nrows=8, hspace=0.5, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = CapsNet(routing_iterations, n_classes)\n",
    "\n",
    "if with_reconstruction:\n",
    "    reconstruction_model = ReconstructionNet(16, n_classes)\n",
    "    reconstruction_alpha = 0.5\n",
    "    model = CapsNetWithReconstruction(model, reconstruction_model)\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=15, min_lr=1e-6)\n",
    "\n",
    "loss_fn = MarginLoss(0.9, 0.1, 0.5)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target, requires_grad=False)\n",
    "        optimizer.zero_grad()\n",
    "        if with_reconstruction:\n",
    "            output, probs = model(data, target)\n",
    "            reconstruction_loss = F.mse_loss(output, data.view(-1, 784))\n",
    "            margin_loss = loss_fn(probs, target)\n",
    "            loss = reconstruction_alpha * reconstruction_loss + margin_loss\n",
    "        else:\n",
    "            output, probs = model(data)\n",
    "            loss = loss_fn(probs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                        100. * batch_idx / len(train_loader), loss.data.item()))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "\n",
    "        if with_reconstruction:\n",
    "            output, probs = model(data, target)\n",
    "            reconstruction_loss = F.mse_loss(output, data.view(-1, 784), size_average=False).data.item()\n",
    "            test_loss += loss_fn(probs, target, size_average=False).data.item()\n",
    "            test_loss += reconstruction_alpha * reconstruction_loss\n",
    "        else:\n",
    "            output, probs = model(data)\n",
    "            test_loss += loss_fn(probs, target, size_average=False).data.item()\n",
    "\n",
    "        pred = probs.data.max(1, keepdim=True)[1]  # get the index of the max probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_dir = \"pretrained_models/\"\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    test_loss = test()\n",
    "    scheduler.step(test_loss)\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(model.state_dict(), dst_dir +\n",
    "                    '{:03d}_model_dict_{}routing_reconstruction{}.pth'.format(epoch, routing_iterations,\n",
    "                                                                            with_reconstruction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1x28x28 tensor input)\n",
    "def get_digit_caps(model, image):\n",
    "    input_ = Variable(image.unsqueeze(0), volatile=True)\n",
    "    digit_caps, probs = model.capsnet(input_)\n",
    "    return digit_caps\n",
    "\n",
    "# takes digit_caps output and target label\n",
    "def get_reconstruction(model, digit_caps, label):\n",
    "    target = Variable(torch.LongTensor([label]), volatile=True)\n",
    "    reconstruction = model.reconstruction_net(digit_caps, target)\n",
    "    return reconstruction.data.cpu().numpy()[0].reshape(28, 28)\n",
    "\n",
    "# create reconstructions with perturbed digit capsule\n",
    "def dimension_perturbation_reconstructions(model, digit_caps, label, dimension, dim_values):\n",
    "    reconstructions = []\n",
    "    for dim_value in dim_values:\n",
    "        digit_caps_perturbed = digit_caps.clone()\n",
    "        digit_caps_perturbed[0, label, dimension] = dim_value\n",
    "        reconstruction = get_reconstruction(model, digit_caps_perturbed, label)\n",
    "        reconstructions.append(reconstruction)\n",
    "    return reconstructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GraphemesDataset(root_dir, test_size=0, by_letter=letter, transform=img_transform)\n",
    "\n",
    "# Get reconstructions\n",
    "images = []\n",
    "reconstructions = []\n",
    "# sample 8 random images from the dataset\n",
    "idx = np.random.randint(0, len(dataset), size=8)\n",
    "for i in idx:\n",
    "    image_tensor, label = dataset[i]\n",
    "    digit_caps = get_digit_caps(model, image_tensor)\n",
    "    reconstruction = get_reconstruction(model, digit_caps, label)\n",
    "    images.append(image_tensor.numpy()[0])\n",
    "    reconstructions.append(reconstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reconstructions\n",
    "fig, axs = plt.subplots(2, 8, figsize=(16, 4))\n",
    "axs[0, 0].set_ylabel('Org image', size='large')\n",
    "axs[1, 0].set_ylabel('Reconstruction', size='large')\n",
    "for i in range(8):\n",
    "    axs[0, i].imshow(images[i], cmap='gray')\n",
    "    axs[1, i].imshow(reconstructions[i], cmap='gray')\n",
    "    axs[0, i].set_yticks([])\n",
    "    axs[0, i].set_xticks([])\n",
    "    axs[1, i].set_yticks([])\n",
    "    axs[1, i].set_xticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What the individual dimensions of a capsule represent\n",
    "\n",
    "We can visualize what an individual dimension of a capsule represents by perturbing values of each dimension (sec. 5.1. of the paper, figure 4).\n",
    "Each row shows the reconstruction when one of the 16 dimensions in the DigitCaps representation is tweaked by intervals of 0.05 in the range [−0.25, 0.25]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit, label = dataset[0]\n",
    "perturbed_reconstructions = []\n",
    "perturbation_values = [0.05*i for i in range(-5, 6)]\n",
    "digit_caps = get_digit_caps(model, digit)\n",
    "for dimension in range(16):\n",
    "    perturbed_reconstructions.append(\n",
    "        dimension_perturbation_reconstructions(model, digit_caps, label,\n",
    "                                               dimension, perturbation_values)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(16, 11, figsize=(11*1.5, 16*1.5))\n",
    "for i in range(16):\n",
    "    axs[i, 0].set_ylabel('dim {}'.format(i), size='large')\n",
    "    for j in range(11):\n",
    "        axs[i, j].imshow(perturbed_reconstructions[i][j], cmap='gray')\n",
    "        axs[i, j].set_yticks([])\n",
    "        axs[i, j].set_xticks([])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
